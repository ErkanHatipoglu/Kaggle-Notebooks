{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27057691",
   "metadata": {
    "papermill": {
     "duration": 0.008068,
     "end_time": "2022-12-10T22:23:46.477361",
     "exception": false,
     "start_time": "2022-12-10T22:23:46.469293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction  <a id='introduction'></a>\n",
    "\n",
    "This notebook contains Python code for a multivariate linear regression task. Multivariate linear regression means linear regression with more than one variable. In addition to Python, we will also use Pandas, Numpy, and Matplotlib libraries. \n",
    "\n",
    "In my [Univariate Linear Regression from Scratch](https://www.kaggle.com/code/erkanhatipoglu/univariate-linear-regression-from-scratch) notebook, we have already seen basic Machine Learning concepts such as the hypothesis, cost function, and gradient descent. We will not explain those concepts in this notebook. Anyone interested may refer to my Kaggle notebook [Univariate Linear Regression from Scratch](https://www.kaggle.com/code/erkanhatipoglu/univariate-linear-regression-from-scratch) or my Medium blog post [Univariate Linear Regression from Scratch](https://medium.com/towards-artificial-intelligence/univariate-linear-regression-from-scratch-68065fe8eb09) published in [Towards AI](https://pub.towardsai.net/) for a more detailed explanation. We will use a gradient descent solution and not discuss the 'normal equation.'\n",
    "\n",
    "This notebook is greatly inspired by the famous Machine Learning course by [Andrew Ng](https://www.andrewng.org/). All the mistakes, if any, are made by me.\n",
    "\n",
    "Finally, thanks to [@Mohan S Acharya](https://www.kaggle.com/mohansacharya) for this dataset.\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "* [Introduction](#introduction)\n",
    "* [Vectorization](#vector)\n",
    "* [Helper functions](#functions)\n",
    "* [The Hypothesis](#hypothesis)\n",
    "* [The Cost Function](#cost)\n",
    "* [Gradient Descent](#gradient)\n",
    "* [Feature Normalization](#normalization)\n",
    "* [Loading Data](#getdata)\n",
    "* [Model Training](#training)\n",
    "* [Model Validation](#validation)\n",
    "* [Conclusion](#conclusion)\n",
    "* [References](#references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8c1c13",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:46.492619Z",
     "iopub.status.busy": "2022-12-10T22:23:46.492135Z",
     "iopub.status.idle": "2022-12-10T22:23:49.074195Z",
     "shell.execute_reply": "2022-12-10T22:23:49.070238Z"
    },
    "papermill": {
     "duration": 2.595921,
     "end_time": "2022-12-10T22:23:49.080112",
     "exception": false,
     "start_time": "2022-12-10T22:23:46.484191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/graduate-admissions/Admission_Predict.csv\n",
      "/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f4104",
   "metadata": {
    "papermill": {
     "duration": 0.005966,
     "end_time": "2022-12-10T22:23:49.096136",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.090170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Vectorization   <a id='vector'></a>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620fc2ba",
   "metadata": {
    "papermill": {
     "duration": 0.019787,
     "end_time": "2022-12-10T22:23:49.135650",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.115863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Tip: Instead of using loops in our Machine Learning functions, we can take advantage of matrices and vectors found in linear algebra libraries that are either built-in to a programming language or easily accessible. This concept is called vectorization.\n",
    "\n",
    "Those linear algebra libraries are generally well-written and highly optimized. So, by using them, our code will be more efficient and more straightforward. In this notebook, we will use the [NumPy](https://numpy.org/) library in Python for this purpose.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cbfcc",
   "metadata": {
    "papermill": {
     "duration": 0.016268,
     "end_time": "2022-12-10T22:23:49.168549",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.152281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions   <a id='functions'></a>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05bdd59",
   "metadata": {
    "papermill": {
     "duration": 0.019182,
     "end_time": "2022-12-10T22:23:49.194782",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.175600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Tip: We will use some helper functions throughout the notebook. Collecting them in one place is a good idea, making the code more organized. First, we will define and explain those functions and then use them in our code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e1ade",
   "metadata": {
    "papermill": {
     "duration": 0.023488,
     "end_time": "2022-12-10T22:23:49.252531",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.229043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The  Hypothesis   <a id='hypothesis'></a>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bcce67",
   "metadata": {
    "papermill": {
     "duration": 0.015812,
     "end_time": "2022-12-10T22:23:49.293024",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.277212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The hypothesis for a linear regression task with multiple variables is of the form: \n",
    "\n",
    "\n",
    "$\\hat{y} = h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$\n",
    "\n",
    "\n",
    "Where $\\hat{y} = h_\\theta(x)$ is the predicted target. The hypothesis will calculate the predicted values (or predicted targets) for a given set of inputs and $\\theta$ values ($\\theta_i$, where $i = 0,1,2,...,n$). \n",
    "\n",
    "\n",
    "Using vector notation, this equation can be rewritten as: \n",
    "\n",
    "\n",
    "$ h_\\theta(x) = \\begin{bmatrix}\\theta_{0} & \\theta_{1} & \\cdots & \\theta_{n}\n",
    "\\end{bmatrix} \\begin{bmatrix}x_{0}\\\\\n",
    "x_{1}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}= \\boldsymbol{\\theta}^T\\boldsymbol{x}$\n",
    "\n",
    "assuming $ \\boldsymbol{\\theta}$ and $\\boldsymbol{x}$ are column vectors and $\\boldsymbol{x_0 = 1}$.\n",
    "\n",
    "Each row in our dataset represents a sample such that:\n",
    "\n",
    "$ \\boldsymbol{X} = \\begin{bmatrix}x_{0}^{(1)} & x_{1}^{(1)} & \\cdots  & x_{n}^{(1)} \\\\\n",
    "x_{0}^{(2)} & x_{1}^{(2)} & \\cdots  & x_{n}^{(2)}\\\\\n",
    "\\vdots & \\vdots & \\vdots  & \\vdots\\\\\n",
    "x_{0}^{(m)} & x_{1}^{(m)} & \\cdots  & x_{n}^{(m)}\n",
    "\\end{bmatrix} and;$ \n",
    "\n",
    "$ \\boldsymbol{\\theta} = \\begin{bmatrix}\\theta_{0} \\\\\n",
    "\\theta_{1}\\\\\n",
    "\\vdots \\\\\n",
    "\\theta_{n}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Where $ \\boldsymbol{X} $ is the training or test dataset, $ \\boldsymbol{\\theta} $ is the $ \\theta $ vector, m is the number of samples, and n is the number of features. As a result, we can calculate the hypothesis as a column vector of $ (m x 1) $ as follows: \n",
    "\n",
    "$ h_\\theta(x) = \\boldsymbol{X}\\boldsymbol{\\theta} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d098a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:49.334774Z",
     "iopub.status.busy": "2022-12-10T22:23:49.334245Z",
     "iopub.status.idle": "2022-12-10T22:23:49.362592Z",
     "shell.execute_reply": "2022-12-10T22:23:49.356672Z"
    },
    "papermill": {
     "duration": 0.050905,
     "end_time": "2022-12-10T22:23:49.365840",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.314935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The hypothesis\n",
    "def h(x, theta):\n",
    "    \"\"\"\n",
    "    calculates the predicted values (or predicted targets) for a given set of input and theta vectors.\n",
    "    :param x: inputs (feature values) - data frame of floats \n",
    "    :param theta: theta vector (weights) - Numpy array of floats\n",
    "    :return: predicted targets - Numpy array of floats\n",
    "    \n",
    "    \"\"\"\n",
    "    # The hypothesis is a column vector of m x 1\n",
    "    return np.dot(x, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf44729",
   "metadata": {
    "papermill": {
     "duration": 0.01216,
     "end_time": "2022-12-10T22:23:49.394725",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.382565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The  Cost Function   <a id='cost'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953724c",
   "metadata": {
    "papermill": {
     "duration": 0.015189,
     "end_time": "2022-12-10T22:23:49.418305",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.403116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will use the squared error cost function as in the univariate linear regression case. Therefore, the cost function is:\n",
    "\n",
    "$ J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m} (h_{\\theta}(x^{(i)})-y^i)^2 $\n",
    "\n",
    "where $m$ is the number of examples, $h_\\theta()$ is the hypothesis function, $ x^i $ is the $i^{th}$ training example, and $y^i$ is the actual output of $i^{th}$ training example. And the vectorized form of the cost function is as follows:\n",
    "\n",
    "$ J(\\theta) = \\frac{1}{2m}( X\\theta - \\vec y)^T(X\\theta - \\vec y) $\n",
    "\n",
    "where $m$ is the number of examples, $X$ is the training or test dataset, $ \\boldsymbol{\\theta} $ is the $ \\theta $ vector, $\\vec y$ is the vector of corresponding $y$ values, and $()^T$ is the transpose of the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb864ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:49.448768Z",
     "iopub.status.busy": "2022-12-10T22:23:49.446187Z",
     "iopub.status.idle": "2022-12-10T22:23:49.456263Z",
     "shell.execute_reply": "2022-12-10T22:23:49.454296Z"
    },
    "papermill": {
     "duration": 0.039717,
     "end_time": "2022-12-10T22:23:49.464511",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.424794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The cost function\n",
    "\n",
    "def J(X,y,theta):\n",
    "    \"\"\"\n",
    "     Calculates the total error using squared error function.\n",
    "    :param X: inputs (feature values) - data frame of floats\n",
    "    :param y: outputs (actual target values) - Numpy array of floats\n",
    "    :param theta: theta vector (weights) - Numpy array of floats\n",
    "    :return: total error - float\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate number of examples\n",
    "    m = len(X)\n",
    "    \n",
    "    # Calculate the constant\n",
    "    c = 1/(2 * m)\n",
    "       \n",
    "    # Calculate the array of errors\n",
    "    temp_0 = h(X, theta) - y.reshape(-1)\n",
    "\n",
    "    # Calculate the transpose of array of errors\n",
    "    temp_1 = temp_0.transpose()\n",
    "\n",
    "    # Calculate the dot product \n",
    "    temp_2 = np.dot(temp_1, temp_0) \n",
    "\n",
    "    return  c * temp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69408b31",
   "metadata": {
    "papermill": {
     "duration": 0.006544,
     "end_time": "2022-12-10T22:23:49.486373",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.479829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gradient Descent   <a id='gradient'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e53739",
   "metadata": {
    "papermill": {
     "duration": 0.00592,
     "end_time": "2022-12-10T22:23:49.506694",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.500774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The gradient descent calculation is similar to what we have seen in the [univariate version](https://www.kaggle.com/code/erkanhatipoglu/univariate-linear-regression-from-scratch?kernelSessionId=106646889):\n",
    "\n",
    "$  \\text{repeat  until  convergence:  \\{} $\n",
    "\n",
    "$\\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m} (h_{\\theta}(x^{(i)})-y^{(i)}).x_0^{(i)}$\n",
    "\n",
    "$\\theta_1 := \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m} (h_{\\theta}(x^{(i)})-y^{(i)}).x_1^{(i)}$\n",
    "\n",
    "$\\theta_2 := \\theta_2 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m} (h_{\\theta}(x^{(i)})-y^{(i)}).x_2^{(i)}$\n",
    "\n",
    "$\\cdots $\n",
    "\n",
    "$\\theta_n := \\theta_n - \\alpha\\frac{1}{m}\\sum_{i=1}^{m} (h_{\\theta}(x^{(i)})-y^{(i)}).x_n^{(i)}$\n",
    "\n",
    "$  \\text{ \\}}$\n",
    "\n",
    "where\n",
    "\n",
    "$n$ is the number of features,\n",
    "\n",
    "$\\theta_j$ (for $j = 0,1,2,\\cdots,n$) is the corresponding weights for each feature, \n",
    "\n",
    "$\\alpha$ is the learning rate, \n",
    "\n",
    "$m$ is the number of examples, \n",
    "\n",
    "$h_{\\theta}(x^{(i)})$ is the result of the hypothesis function for the $i^{th}$ training example, \n",
    "\n",
    "$y^{(i)}$ is the actual value for the $i^{th}$ training example,\n",
    "\n",
    "and $x_k^{(i)}$ (for $k = 0,1,2,\\cdots,n$) is the value of the $k^{th}$ feature for the $i^{th}$ training example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee950f",
   "metadata": {
    "papermill": {
     "duration": 0.006467,
     "end_time": "2022-12-10T22:23:49.527680",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.521213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Therefore, the vectorized form of the gradient descent is as follows: \n",
    "\n",
    "$ \\boldsymbol{\\theta} := \\boldsymbol{\\theta} - \\frac{\\alpha}{m} \\boldsymbol{X}^T (\\boldsymbol{X}\\boldsymbol{\\theta} - \\vec y) $\n",
    "\n",
    "where $ \\boldsymbol{\\theta} $ is the $ \\theta $ vector, $\\alpha$ is the learning rate, $m$ is the number of examples, $X$ is the training or test dataset, $()^T$ is the transpose of the matrix, and $\\vec y$ is the vector of corresponding $y$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b5e1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:49.561923Z",
     "iopub.status.busy": "2022-12-10T22:23:49.559796Z",
     "iopub.status.idle": "2022-12-10T22:23:49.583739Z",
     "shell.execute_reply": "2022-12-10T22:23:49.576231Z"
    },
    "papermill": {
     "duration": 0.046469,
     "end_time": "2022-12-10T22:23:49.590777",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.544308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gradient descent function\n",
    "def gradient(X, y, theta, alpha):\n",
    "    \"\"\"\n",
    "     calculates the gradient descent.\n",
    "    :param X: inputs (feature values) - data frame of floats\n",
    "    :param y: outputs (actual target values) - Numpy array of floats\n",
    "    :param theta: theta vector (weights) - Numpy array of floats\n",
    "    :param alpha: learning rate\n",
    "    :return: new theta - Numpy array of floats\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate number of examples\n",
    "    m = len(X)\n",
    "    \n",
    "    # Calculate the constant\n",
    "    c =  alpha / m\n",
    "        \n",
    "    # calculate the transpose of X\n",
    "    temp_0 = X.transpose()\n",
    "        \n",
    "    # Calculate the array of errors\n",
    "    temp_1 = h(X, theta) - y.reshape(-1) \n",
    "        \n",
    "    # Calculate the dot product \n",
    "    temp_2 = np.dot(temp_0, temp_1)\n",
    "        \n",
    "    return theta - (c * temp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f772c",
   "metadata": {
    "papermill": {
     "duration": 0.012771,
     "end_time": "2022-12-10T22:23:49.614753",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.601982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Normalization  <a id='normalization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62b044",
   "metadata": {
    "papermill": {
     "duration": 0.008143,
     "end_time": "2022-12-10T22:23:49.634555",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.626412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Tip: Making the feature values approximately the same scale (i.e., a similar range of values) speeds up the gradient descent. Therefore in this notebook, we will scale some features in our dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd0ec3",
   "metadata": {
    "papermill": {
     "duration": 0.021125,
     "end_time": "2022-12-10T22:23:49.671841",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.650716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are various techniques for normalization; we will present three of them:\n",
    "\n",
    "**Standardization:** $\\frac{X-X.mean}{X.std}$\n",
    "\n",
    "**Mean Normalization** $\\frac{X-X.mean}{X.max - X.min}$\n",
    "\n",
    "**Min-Max Scaling:** $\\frac{X-X.min}{X.max - X.min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a5c051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:49.704036Z",
     "iopub.status.busy": "2022-12-10T22:23:49.703139Z",
     "iopub.status.idle": "2022-12-10T22:23:49.720533Z",
     "shell.execute_reply": "2022-12-10T22:23:49.714118Z"
    },
    "papermill": {
     "duration": 0.041657,
     "end_time": "2022-12-10T22:23:49.730518",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.688861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalization and Standardization\n",
    "def normalize(X):\n",
    "    \"\"\"\n",
    "     Applies standardization to the dataframe.\n",
    "    :param X: unnormalized features - data frame of floats\n",
    "    :return: normalized features - data frame of floats\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = ['GRE Score', 'TOEFL Score', 'CGPA']\n",
    "    for column in columns:\n",
    "        \n",
    "        # Use this if you want Z-Score Normalization (or Standardization).\n",
    "        # Note that you must play with the learning rate\n",
    "        # and convergence threshold for better results.        \n",
    "        # X[column] = (X[column] - X[column].mean()) / X[column].std()\n",
    "        \n",
    "        # Use this if you want Mean Normalization.\n",
    "        # Note that you must play with the learning rate\n",
    "        # and convergence threshold for better results.        \n",
    "        # X[column] = (X[column] - X[column].mean()) / (X[column].max() - X[column].min()) or\n",
    "                \n",
    "        # Use this if you want Min-Max Scaling (or Min-Max Normalization).\n",
    "        # Note that you must play with the learning rate\n",
    "        # and convergence threshold for better results.  \n",
    "        # X[column] = (X[column] - X[column].min()) / (X[column].max() - X[column].min())\n",
    "        \n",
    "        # We will use Min-Max Scaling.\n",
    "        X[column] = (X[column] - X[column].min()) / (X[column].max() - X[column].min())\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cd680",
   "metadata": {
    "papermill": {
     "duration": 0.007191,
     "end_time": "2022-12-10T22:23:49.748023",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.740832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data   <a id='getdata'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328a7921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:49.783729Z",
     "iopub.status.busy": "2022-12-10T22:23:49.782815Z",
     "iopub.status.idle": "2022-12-10T22:23:49.910359Z",
     "shell.execute_reply": "2022-12-10T22:23:49.909635Z"
    },
    "papermill": {
     "duration": 0.147133,
     "end_time": "2022-12-10T22:23:49.912491",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.765358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.852564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.637821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR       CGPA  Research\n",
       "107       0.96     0.892857                  4  3.5   4.5  0.852564         1\n",
       "336       0.58     0.642857                  3  3.0   2.5  0.637821         0\n",
       "71        0.92     0.714286                  5  5.0   5.0  0.948718         1\n",
       "474       0.36     0.464286                  4  3.0   2.5  0.368590         1\n",
       "6         0.62     0.607143                  3  3.0   4.0  0.448718         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data. Note that there are two versions. We will use the one\n",
    "# with the most rows.\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv\")\n",
    "\n",
    "# Set X and y\n",
    "X = train_data.drop(['Chance of Admit ', 'Serial No.'], axis=1) # Chance of Admit is the target variable and Serial No. is the order. So we drop them.\n",
    "y = pd.DataFrame(data = train_data['Chance of Admit ']).to_numpy()\n",
    "\n",
    "# \n",
    "X = normalize(X)\n",
    "\n",
    "# Instead of finding probabilities, we want to calculate the percentages.\n",
    "y = y * 100\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state = 0)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268d8e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:49.936651Z",
     "iopub.status.busy": "2022-12-10T22:23:49.935509Z",
     "iopub.status.idle": "2022-12-10T22:23:49.978723Z",
     "shell.execute_reply": "2022-12-10T22:23:49.971218Z"
    },
    "papermill": {
     "duration": 0.066349,
     "end_time": "2022-12-10T22:23:49.986822",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.920473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.852564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.637821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR       CGPA  Research\n",
       "107       0.96     0.892857                  4  3.5   4.5  0.852564         1\n",
       "336       0.58     0.642857                  3  3.0   2.5  0.637821         0\n",
       "71        0.92     0.714286                  5  5.0   5.0  0.948718         1\n",
       "474       0.36     0.464286                  4  3.0   2.5  0.368590         1\n",
       "6         0.62     0.607143                  3  3.0   4.0  0.448718         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bec91c",
   "metadata": {
    "papermill": {
     "duration": 0.007734,
     "end_time": "2022-12-10T22:23:50.006580",
     "exception": false,
     "start_time": "2022-12-10T22:23:49.998846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training   <a id='training'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3feb309",
   "metadata": {
    "papermill": {
     "duration": 0.012909,
     "end_time": "2022-12-10T22:23:50.034153",
     "exception": false,
     "start_time": "2022-12-10T22:23:50.021244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model training content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8850a91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:50.069669Z",
     "iopub.status.busy": "2022-12-10T22:23:50.069277Z",
     "iopub.status.idle": "2022-12-10T22:23:50.172699Z",
     "shell.execute_reply": "2022-12-10T22:23:50.171041Z"
    },
    "papermill": {
     "duration": 0.128828,
     "end_time": "2022-12-10T22:23:50.175643",
     "exception": false,
     "start_time": "2022-12-10T22:23:50.046815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial Cost: 2741.2200000000003\n",
      "\n",
      "Iteration: 1\n",
      "Calculated cost: 1803.536465562745\n",
      "cost difference: 937.6835344372553\n",
      "\n",
      "Iteration: 2\n",
      "Calculated cost: 1194.666514354635\n",
      "cost difference: 608.86995120811\n",
      "\n",
      "Iteration: 3\n",
      "Calculated cost: 799.3013538757673\n",
      "cost difference: 395.36516047886767\n",
      "\n",
      "Iteration: 4\n",
      "Calculated cost: 542.5688457291143\n",
      "cost difference: 256.732508146653\n",
      "\n",
      "Iteration: 5\n",
      "Calculated cost: 375.85312124304767\n",
      "cost difference: 166.71572448606662\n",
      "\n",
      "Iteration: 6\n",
      "Calculated cost: 267.586994808255\n",
      "cost difference: 108.26612643479268\n",
      "\n",
      "Iteration: 7\n",
      "Calculated cost: 197.2733070302654\n",
      "cost difference: 70.31368777798957\n",
      "\n",
      "Iteration: 8\n",
      "Calculated cost: 151.6028719171572\n",
      "cost difference: 45.670435113108226\n",
      "\n",
      "Iteration: 9\n",
      "Calculated cost: 121.9337879653226\n",
      "cost difference: 29.669083951834594\n",
      "\n",
      "Iteration: 10\n",
      "Calculated cost: 102.65470808144767\n",
      "cost difference: 19.279079883874928\n",
      "\n",
      "Iteration: 11\n",
      "Calculated cost: 90.12208037681452\n",
      "cost difference: 12.532627704633143\n",
      "\n",
      "Iteration: 12\n",
      "Calculated cost: 81.97007889780986\n",
      "cost difference: 8.152001479004667\n",
      "\n",
      "Iteration: 13\n",
      "Calculated cost: 76.66252884647793\n",
      "cost difference: 5.30755005133193\n",
      "\n",
      "Iteration: 14\n",
      "Calculated cost: 73.20196331315147\n",
      "cost difference: 3.4605655333264593\n",
      "\n",
      "Iteration: 15\n",
      "Calculated cost: 70.94070841511464\n",
      "cost difference: 2.2612548980368246\n",
      "\n",
      "Iteration: 16\n",
      "Calculated cost: 69.45821737222248\n",
      "cost difference: 1.482491042892164\n",
      "\n",
      "Iteration: 17\n",
      "Calculated cost: 68.4814212463933\n",
      "cost difference: 0.976796125829182\n",
      "\n",
      "Iteration: 18\n",
      "Calculated cost: 67.83301119903675\n",
      "cost difference: 0.6484100473565491\n",
      "\n",
      "Iteration: 19\n",
      "Calculated cost: 67.39785720128711\n",
      "cost difference: 0.43515399774963726\n",
      "\n",
      "Iteration: 20\n",
      "Calculated cost: 67.10120307952614\n",
      "cost difference: 0.29665412176096595\n",
      "\n",
      "Iteration: 21\n",
      "Calculated cost: 66.89450815389439\n",
      "cost difference: 0.2066949256317514\n",
      "\n",
      "Iteration: 22\n",
      "Calculated cost: 66.7462539514959\n",
      "cost difference: 0.14825420239849052\n",
      "\n",
      "Iteration: 23\n",
      "Calculated cost: 66.63597483471817\n",
      "cost difference: 0.11027911677773261\n",
      "\n",
      "Iteration: 24\n",
      "Calculated cost: 66.55038197744864\n",
      "cost difference: 0.08559285726953192\n",
      "\n",
      " Calculated theta: [2.03692557 1.13926025 1.14289218 6.02902784 6.60181418 6.82324225\n",
      " 1.20521232 1.25048269]\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "\n",
    "\n",
    "# Calculate the number of examles\n",
    "m_train = len(X_train)\n",
    "m_valid = len(X_valid)\n",
    "\n",
    "# Calculate the number of features\n",
    "# including X_0\n",
    "n = len(X_train.axes[1]) + 1\n",
    "\n",
    "# Make a list of ones\n",
    "ones_train = [1] * m_train\n",
    "ones_valid = [1] * m_valid\n",
    "\n",
    "# Insert ones to the fist column since\n",
    "# X_0 for all training examples should\n",
    "# be one.\n",
    "X_train.insert(0, \"X_0\", ones_train, True)\n",
    "X_valid.insert(0, \"X_0\", ones_valid, True)\n",
    "\n",
    "# Select zero vector for initial theta\n",
    "zero_list= [0] * n\n",
    "theta = np.asarray(zero_list)\n",
    "\n",
    "# set learning rate \n",
    "alpha = 0.005\n",
    "\n",
    "# Set convergence threshold\n",
    "threshold = 0.1\n",
    "\n",
    "# Initial cost value.\n",
    "# Will also be used in the first iteration\n",
    "# of the while loop. If the initial cost\n",
    "# is smaller then convergence threshold then\n",
    "# while loop will not be executed.\n",
    "cost_diff = J(X_train, y_train, theta)\n",
    "print(\"initial Cost: {}\".format(cost_diff))\n",
    "\n",
    "# We will count the number of iterations.\n",
    "my_iter = 0\n",
    "\n",
    "# Create a dictionary of cost values for debugging\n",
    "cost_dict = {} # will be used for storing the cost value of each iteration.\n",
    "\n",
    "# Add initial cost value to the dictionary\n",
    "my_key = \"I_\" + str(my_iter)\n",
    "cost_dict[my_key] = cost_diff\n",
    "\n",
    "# Start gradient descent\n",
    "while cost_diff >= threshold:\n",
    "    \n",
    "    # calculate initial cost value\n",
    "    initial_cost = J(X_train, y_train, theta)\n",
    "    \n",
    "    # calculate and assign the new theta values\n",
    "    theta = gradient(X_train, y_train, theta, alpha)\n",
    "    \n",
    "    # calculate the consecutive cost value\n",
    "    new_cost = J(X_train, y_train, theta)\n",
    "        \n",
    "    # calculate the difference between the consecutive\n",
    "    # cost values\n",
    "    cost_diff = initial_cost - new_cost\n",
    "    \n",
    "    # Update the dictionary\n",
    "    my_key = \"I_\" + str(my_iter)\n",
    "    cost_dict[my_key] = new_cost\n",
    "    \n",
    "    my_iter += 1\n",
    "    \n",
    "    print()\n",
    "    print(\"Iteration: {}\".format(my_iter))\n",
    "    print(\"Calculated cost: {}\".format(new_cost))\n",
    "    print(\"cost difference: {}\".format(cost_diff))\n",
    "\n",
    "print(\"\\n Calculated theta: {}\".format(theta))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75dec78a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:50.205174Z",
     "iopub.status.busy": "2022-12-10T22:23:50.204797Z",
     "iopub.status.idle": "2022-12-10T22:23:50.873146Z",
     "shell.execute_reply": "2022-12-10T22:23:50.865865Z"
    },
    "papermill": {
     "duration": 0.692853,
     "end_time": "2022-12-10T22:23:50.880942",
     "exception": false,
     "start_time": "2022-12-10T22:23:50.188089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb82126fb50>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Debugging Curve\n",
    "Y1=[x for x in cost_dict.values()]\n",
    "\n",
    "X1=[x for x in cost_dict.keys()]\n",
    "\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('J()')\n",
    "plt.title('Debugging Curve')\n",
    "plt.plot(X1,Y1, color='tab:blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c77785",
   "metadata": {
    "papermill": {
     "duration": 0.008008,
     "end_time": "2022-12-10T22:23:50.905689",
     "exception": false,
     "start_time": "2022-12-10T22:23:50.897681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Validation   <a id='validation'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c2e3e",
   "metadata": {
    "papermill": {
     "duration": 0.01306,
     "end_time": "2022-12-10T22:23:50.934819",
     "exception": false,
     "start_time": "2022-12-10T22:23:50.921759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "model validation content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9972c8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:23:50.964495Z",
     "iopub.status.busy": "2022-12-10T22:23:50.964135Z",
     "iopub.status.idle": "2022-12-10T22:23:50.972580Z",
     "shell.execute_reply": "2022-12-10T22:23:50.970492Z"
    },
    "papermill": {
     "duration": 0.040474,
     "end_time": "2022-12-10T22:23:50.986086",
     "exception": false,
     "start_time": "2022-12-10T22:23:50.945612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " theta: [2.03692557 1.13926025 1.14289218 6.02902784 6.60181418 6.82324225\n",
      " 1.20521232 1.25048269]\n",
      "\n",
      "Cost of test data: 76.48149798139413\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n theta: {}\\n\".format(theta))\n",
    "\n",
    "# calculate the cost value for the test set\n",
    "cost_test = J(X_valid, y_valid, theta)\n",
    "print(\"Cost of test data: {}\".format(cost_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83dd8e",
   "metadata": {
    "papermill": {
     "duration": 0.011554,
     "end_time": "2022-12-10T22:23:51.023413",
     "exception": false,
     "start_time": "2022-12-10T22:23:51.011859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion   <a id='conclusion'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d8f91",
   "metadata": {
    "papermill": {
     "duration": 0.007811,
     "end_time": "2022-12-10T22:23:51.045282",
     "exception": false,
     "start_time": "2022-12-10T22:23:51.037471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Conclusion content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65daa673",
   "metadata": {
    "papermill": {
     "duration": 0.012045,
     "end_time": "2022-12-10T22:23:51.074052",
     "exception": false,
     "start_time": "2022-12-10T22:23:51.062007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# References   <a id='references'></a>\n",
    "* [Machine Learning Specialization - Deeplearning.AI](https://www.deeplearning.ai/program/machine-learning-specialization/)\n",
    "* [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng)\n",
    "* [@Mohan S Acharya](https://www.kaggle.com/mohansacharya)\n",
    "* [10-simple-hacks-to-speed-up-your-data-analysis - Parul Pandey](https://www.kaggle.com/parulpandey/10-simple-hacks-to-speed-up-your-data-analysis)\n",
    "* [Univariate Linear Regression From Scratch - Kaggle](https://www.kaggle.com/code/erkanhatipoglu/univariate-linear-regression-from-scratch)\n",
    "* [Univariate Linear Regression From Scratch - Towards AI](https://pub.towardsai.net/univariate-linear-regression-from-scratch-68065fe8eb09)\n",
    "* [Towards AI](https://pub.towardsai.net/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.906549,
   "end_time": "2022-12-10T22:23:53.626807",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-10T22:23:33.720258",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
